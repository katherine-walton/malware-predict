# -*- coding: utf-8 -*-
"""rf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xoIniwzogFMXAe6LW4UHSbbU7JGhfDQL

Imports all of the datasets and libraries
"""

from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from collections import OrderedDict
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/open?id=1-MaLI6jDK6eC88b1NmIpLF-9OgifB1Ea'
fluff, id = link.split('=')
downloaded = drive.CreateFile({'id':id}) 
downloaded.GetContentFile('xTrain.csv')  
xTrain = pd.read_csv('xTrain.csv')

link = 'https://drive.google.com/open?id=1-Bip173de0Pl1P9tlABG1fPMIQ-Hdgge'
fluff, id = link.split('=')
downloaded = drive.CreateFile({'id':id}) 
downloaded.GetContentFile('yTrain.csv')  
yTrain = pd.read_csv('yTrain.csv')

link = 'https://drive.google.com/open?id=1-GPB-MdrUl2AaPq4jEv-8nXSuG0wBRD2'
fluff, id = link.split('=')
downloaded = drive.CreateFile({'id':id}) 
downloaded.GetContentFile('xValidation.csv')  
xVal = pd.read_csv('xValidation.csv')

link = 'https://drive.google.com/open?id=1-1yF7E7uvfPVH8K1Kh09qdbqXwynRXih'
fluff, id = link.split('=')
downloaded = drive.CreateFile({'id':id}) 
downloaded.GetContentFile('yValidation.csv')  
yVal = pd.read_csv('yValidation.csv')

link = 'https://drive.google.com/open?id=1-JzBY5ml8uUIbU00Op2IiB3izmqUCW56'
fluff, id = link.split('=')
downloaded = drive.CreateFile({'id':id}) 
downloaded.GetContentFile('xTest.csv')  
xTest = pd.read_csv('xTest.csv')

link = 'https://drive.google.com/open?id=1cGe9MCdwSCeURtmnsWOcU3E0EyB_8cfM'
fluff, id = link.split('=')
downloaded = drive.CreateFile({'id':id}) 
downloaded.GetContentFile('yTest.csv')  
yTest = pd.read_csv('yTest.csv')

"""Method to list all of the optimal decision tree parameters using cross validation"""

def optimal_dt(xTrain,yTrain):
  dt = DecisionTreeClassifier()
  tuned_parameters = {
      'criterion': ['entropy','gini'],
      'max_depth': [5,10,15,20,25,30,35],
      'min_samples_leaf': list(range(50,350,50)),
      'max_features': [0.2,0.3,0.4]
  }
  cv = RandomizedSearchCV(estimator=dt, n_iter = 50, cv = 5,
                        param_distributions = tuned_parameters,
                        random_state=334)
  cv.fit(xTrain,yTrain)
  print(pd.DataFrame(cv.cv_results_)[['param_min_samples_leaf', 'param_max_features', 'param_max_depth', 'param_criterion']])
  print(cv.best_params_)
  print(cv.best_score_)
  print(cv.best_estimator_)

optimal_dt(xTrain,yTrain)

"""Plots the results and AUCs of both models without parameter tuning"""

def unparameterized_results(xTrain,yTrain,xVal,yVal):
    dt = DecisionTreeClassifier()
    dt.fit(xTrain, yTrain)
    dt_yHat_probs = dt.predict_proba(xVal)

    dt_fpr,dt_tpr,_ = metrics.roc_curve(yVal, dt_yHat_probs[:,1])
    dt_auc = metrics.auc(dt_fpr,dt_tpr)
    dt_score = dt.score(xVal, yVal)

    rf = RandomForestClassifier(n_estimators=10)
    rf.fit(xTrain, yTrain)
    rf_yHat_probs = rf.predict_proba(xVal)

    rf_fpr,rf_tpr,_ = metrics.roc_curve(yVal, rf_yHat_probs[:,1])
    rf_auc = metrics.auc(rf_fpr,rf_tpr)
    rf_score = rf.score(xVal, yVal)

    plt.title('Receiver Operating Characteristic')
    plt.plot(dt_fpr, dt_tpr, 'b', label = 'DT AUC = %0.3f' % dt_auc)
    plt.plot(rf_fpr, rf_tpr, 'g', label = 'RF AUC = %0.3f' % rf_auc)
    plt.legend(loc = 'lower right')
    plt.plot([0, 1], [0, 1],'r--')
    plt.xlim([0, 1])
    plt.ylim([0, 1])
    plt.ylabel('True Positive Rate')
    plt.xlabel('False Positive Rate')
    plt.show()



"""Determines the best number of trees for the forest using OOB error rate and plots the results"""

ensemble_clfs = [ ("RandomForestClassifier with hyperparameters",
                   RandomForestClassifier(oob_score=True,  
                              warm_start=True,
                              n_estimators = 100,
                              criterion = 'gini', 
                              max_features=0.4,
                              min_samples_leaf=300, 
                              max_depth = 20,
                              random_state=334) )]
error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)
min_estimators = 10
max_estimators = 130
for label, clf in ensemble_clfs:
    for i in range(min_estimators, max_estimators + 1,3):
        print(i)
        clf.set_params(n_estimators=i)
        clf.fit(xTrain, yTrain.values.ravel())
        oob_error = 1 - clf.oob_score_
        error_rate[label].append((i, oob_error))

for label, clf_err in error_rate.items():
    xs, ys = zip(*clf_err)
    plt.plot(xs, ys, label=label)

plt.xlim(min_estimators, max_estimators)
plt.xlabel("n_estimators")
plt.ylabel("OOB error rate")
plt.legend(loc="upper right")
plt.show()

"""Now, we actually create the model using the best parameters and plot the results"""

dt = DecisionTreeClassifier(criterion='gini', random_state=334, max_depth = 15, max_features=0.4, min_samples_leaf=350)
dt.fit(xTrain, yTrain.ravel())
dt_yHat_probs = dt.predict_proba(xVal)

dt_fpr,dt_tpr,dt_thresholds = metrics.roc_curve(yVal.ravel(), dt_yHat_probs[:,1])
dt_auc = metrics.auc(dt_fpr,dt_tpr)
dt_score = dt.score(xVal, yVal.ravel())

rf = RandomForestClassifier(n_estimators=50, criterion = 'gini', max_features=0.4,
                              min_samples_leaf=350, max_depth = 15,oob_score=True,
                            random_state=334)
rf.fit(xTrain, yTrain.ravel())
rf_yHat_probs = rf.predict_proba(xVal)

rf_fpr,rf_tpr,rf_thresholds = metrics.roc_curve(yVal.ravel(), rf_yHat_probs[:,1])
rf_auc = metrics.auc(rf_fpr,rf_tpr)
rf_score = rf.score(xVal, yVal.ravel())

plt.title('Receiver Operating Characteristic')
plt.plot(dt_fpr, dt_tpr, 'b', label = 'DT AUC = %0.3f' % dt_auc)
plt.plot(rf_fpr, rf_tpr, 'g', label = 'RF AUC = %0.3f' % rf_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

"""Next, we predict on the Validation and Test sets and save to drive"""

rf_valHat = rf.predict(xVal)
rf_testHat = rf.predict(xTest)

pd.DataFrame(rf_valHat).to_csv("rf_valHat.csv",index=False)
pd.DataFrame(rf_testHat).to_csv("rf_testHat.csv",index=False)

from sklearn.metrics import accuracy_score
print(accuracy_score(yVal, rf_valHat))

print(accuracy_score(yTest, rf_testHat))

from google.colab import drive
drive.mount('/content/drive')
!cp rf_valHat.csv drive/My\ Drive/
!cp rf_testHat.csv drive/My\ Drive/

