import argparse
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

def remove_missing_features(todelete, train):
	"""
	Removes features with large amounts of missing data.
	"""
	missing = []
	for x in range(0, len(train.columns)):
		totals = (sum (train.iloc[:,x].isnull()) ) / len(train)
		missing.append(totals)
		if totals > .99:
			todelete.append(train.columns[x])
	#result = pd.DataFrame(missing, index = list(Train.columns), columns=['Proportion of Missing Data'])
	#result = result.sort_values(by=['Proportion of Missing Data'],ascending=False)
	return todelete

def remove_skewed_features(todelete,data):
    """
    This function will drop columns from the data whose majority category covers more than 99% of occurences.
    """
    # find features where there are hardly any unique values
    # TODO learn more about this and possibly change variable names/appraoch
    sk_df = pd.DataFrame([{'column': c, 'uniq': data[c].nunique(), 'skewness': data[c].value_counts(normalize=True).values[0] * 100} for c in data.columns])
    sk_df = sk_df.sort_values('skewness', ascending = False)
    todelete.extend(sk_df[sk_df.skewness> 99].column.tolist())

    return todelete

def remove_correlated_features(train):
	"""
	Removes features that have high correlation with other features.
	"""
	corrmx = train.corr(method='pearson')
	cols = list(corrmx.columns)
	j = corrmx.shape[1]
	newtest = corrmx.to_numpy()
	col1=[]
	col2=[]
	corr=[]
	for x in range(j):
		for y in range(x+1, j):
			if abs(newtest[x,y]) > .75:
				col1.append(cols[x])
				col2.append(cols[y])
				corr.append(newtest[x,y])
				# print(train[[cols[x],cols[y],'HasDetections']].corr())
	result = pd.DataFrame(np.column_stack([col1,col2,corr]),
						columns=['Feature 1','Feature 2','Correlation'])
	#print(train[[]])
	#print(result)

def main():
	parser = argparse.ArgumentParser()
	parser.add_argument("--trainFile",
						default="train.csv",
						help="filename of the training data")
	args = parser.parse_args()
	Train = pd.read_csv(args.trainFile, nrows=5000)

	todelete = []
	todelete = remove_missing_features(todelete,Train)
	todelete = remove_skewed_features(todelete, Train)
	# TODO make sure elements in todelete list are unique
	# print(todelete)
	remove_correlated_features(Train)




if __name__ == "__main__":
	main()
